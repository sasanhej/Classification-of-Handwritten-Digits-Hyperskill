type: edu
files:
- name: analysis.py
  visible: true
  text: |
    import tensorflow as tf
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.preprocessing import Normalizer
    from sklearn.metrics import accuracy_score
    from warnings import simplefilter
    from sklearn.model_selection import GridSearchCV

    simplefilter(action='ignore', category=FutureWarning)

    (X_train, y_train) = tf.keras.datasets.mnist.load_data(path="mnist.npz")[0]
    X_train = X_train.reshape(-1, 784)
    '''
    #Stage 1/5
    print(f"Classes: {np.unique(y_train)}")
    print(f"Features' shape: {X_train.shape}")
    print(f"Target's shape: {y_train.shape}")
    print(f"min: {X_train.min()}, max: {X_train.max()}")
    '''
    #Stage 2/5
    X_train, X_test, y_train, y_test = train_test_split(X_train[:6000], y_train[:6000], test_size=0.3, random_state=40)
    '''
    print(f"x_train shape: {X_train.shape}")
    print(f"x_test shape: {X_test.shape}")
    print(f"y_train shape: {y_train.shape}")
    print(f"y_test shape: {y_test.shape}")
    print('Proportion of samples per class in train set:')
    print(pd.Series(y_train).value_counts(normalize=True))
    '''
    #Stage 3/5:
    def fit_predict_eval(model, features_train=X_train, features_test=X_test, target_train=y_train, target_test=y_test, random_state=40):
        model.fit(features_train, target_train)
        target_prediction = model.predict(features_test)
        score = np.mean(target_prediction == target_test)
        print(f'Model: {model}\nAccuracy: {score}\n')

    '''
    fit_predict_eval(KNeighborsClassifier())
    fit_predict_eval(DecisionTreeClassifier(random_state=40))
    fit_predict_eval(LogisticRegression(random_state=40))
    fit_predict_eval(RandomForestClassifier(random_state=40))
    print(f'The answer to the question: {"RandomForestClassifier"} - {0.939}')
    '''
    #Stage 4/5:
    X_train_norm = Normalizer().fit_transform(X_train)
    X_test_norm = Normalizer().fit_transform(X_test)

    def fit_predict_eval_norm(model, features_train=X_train_norm, features_test=X_test_norm, target_train=y_train, target_test=y_test, random_state=40):
        model.fit(features_train, target_train)
        target_prediction = model.predict(features_test)
        score = accuracy_score(target_test, target_prediction)
        #print(f'Model: {model}\nAccuracy: {score}\n')

    fit_predict_eval_norm(KNeighborsClassifier())
    fit_predict_eval_norm(DecisionTreeClassifier(random_state=40))
    fit_predict_eval_norm(LogisticRegression(random_state=40))
    fit_predict_eval_norm(RandomForestClassifier(random_state=40))
    #print(f'The answer to the 1st question: yes')
    #print(f'The answer to the 2nd question: {"KNeighborsClassifier"}-{0.953}, {"RandomForestClassifier"}-{0.937}')

    #stage 5/5
    random_state = 40
    models = [KNeighborsClassifier(), RandomForestClassifier(random_state=random_state)]
    param = [{'n_neighbors': [3, 4], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'brute']},
             {'n_estimators': [200, 300], 'max_features': ['auto', 'log2'], 'class_weight': ['balanced', 'balanced_subsample']}]

    optkn = GridSearchCV(estimator=models[0], param_grid=param[0], scoring='accuracy', n_jobs=-1)
    optkn.fit(X_train_norm, y_train)
    optkn = optkn.best_estimator_
    print(f'K-nearest neighbours algorithm\nbest estimator: {optkn}')
    preds = optkn.predict(X_test_norm)
    print(f'accuracy: {round(accuracy_score(preds, y_test), 3)}\n')

    optrf = GridSearchCV(estimator=models[1], param_grid=param[1], scoring='accuracy', n_jobs=-1)
    optrf.fit(X_train_norm, y_train)
    optrf = optrf.best_estimator_
    print(f'Random forest algorithm\nbest estimator: {optrf}')
    preds = optrf.predict(X_test_norm)
    print(f'accuracy: {round(accuracy_score(preds, y_test), 3)}\n')
  learner_created: false
- name: test/__init__.py
  visible: false
  learner_created: false
- name: test/tests.py
  visible: false
  text: |
    from hstest.stage_test import StageTest
    from hstest.test_case import TestCase
    from hstest.check_result import CheckResult
    from sklearn.exceptions import ConvergenceWarning
    import warnings

    import re

    # turn off logistic regression convergence warning
    warnings.filterwarnings("ignore", category=ConvergenceWarning)


    # function to provide better feedback
    def get_model_name(line_reply):
        idx = line_reply.replace(" ", "").lower().index('model:') + len('model:')
        model_name_reply = line_reply.replace(" ", "")[idx:]
        return model_name_reply


    def get_lines_with_key_words(lines, keywords):
        lines_with_keywords = []
        for line in lines:
            if set(line.lower().split()) & set(keywords):
                lines_with_keywords.append(line)
        return lines_with_keywords


    class CCATest(StageTest):

        def generate(self):
            return [TestCase(time_limit=60000)]

        def check(self, reply, attach):
            lines = reply.split('\n')
            if "" in lines:
                lines = list(filter(lambda a: a != "", lines))

            relevant_lines = get_lines_with_key_words(lines, keywords=['model:', 'accuracy:', 'question:'])

            # general
            if len(relevant_lines) != 10:
                return CheckResult.wrong(
                    feedback=f"Expected 10 lines with Model:/Accuracy:/Answer to the 1st question:/Answer to the 2nd question:, found {len(relevant_lines)}\n"
                             f"Note that the order of the models in the output is important (see the Example section)")

            # models and accuracies print
            # 1st model
            model_name_answer = 'KNeighborsClassifier'
            if model_name_answer not in relevant_lines[0]:
                model_name_reply = get_model_name(relevant_lines[0])
                return CheckResult.wrong(feedback=f"Incorrect name of the 1st model\n"
                                                  f"Expected {model_name_answer}, found {model_name_reply}")

            accuracy_reply = re.findall(r'\d*\.\d+|\d+', relevant_lines[1])
            if len(accuracy_reply) != 1:
                return CheckResult.wrong(feedback=f'It should be one number in the "Accuracy:" section')
            # 1% error rate is allowed, right accuracy = 0.953
            if not 0.99 * 0.953 < float(accuracy_reply[0]) < 1.01 * 0.953:
                return CheckResult.wrong(feedback=f"Wrong accuracy for the 1st model")

            # 2nd model
            model_name_answer = 'DecisionTreeClassifier'
            if model_name_answer not in relevant_lines[2]:
                model_name_reply = get_model_name(relevant_lines[2])
                return CheckResult.wrong(feedback=f"Incorrect name of the 1st model\n"
                                                  f"Expected {model_name_answer}, found {model_name_reply}")

            accuracy_reply = re.findall(r'\d*\.\d+|\d+', relevant_lines[3])
            if len(accuracy_reply) != 1:
                return CheckResult.wrong(feedback=f'It should be one number in the "Accuracy:" section')
            # 2% error rate is allowed, right accuracy = 0.781
            if not 0.98 * 0.781 < float(accuracy_reply[0]) < 1.02 * 0.781:
                return CheckResult.wrong(feedback=f"Wrong accuracy for the 2nd model")

            # 3rd model
            model_name_answer = 'LogisticRegression'
            if model_name_answer not in relevant_lines[4]:
                model_name_reply = get_model_name(relevant_lines[4])
                return CheckResult.wrong(feedback=f"Incorrect name of the 1st model\n"
                                                  f"Expected {model_name_answer}, found {model_name_reply}")

            accuracy_reply = re.findall(r'\d*\.\d+|\d+', relevant_lines[5])
            if len(accuracy_reply) != 1:
                return CheckResult.wrong(feedback=f'It should be one number in the "Accuracy:" section')
            # 2% error rate is allowed, right accuracy = 0.895
            if not 0.98 * 0.895 < float(accuracy_reply[0]) < 1.02 * 0.895:
                return CheckResult.wrong(feedback=f"Wrong accuracy for the 3rd model")

            # 4th model
            model_name_answer = 'RandomForestClassifier'
            if model_name_answer not in relevant_lines[6]:
                model_name_reply = get_model_name(relevant_lines[6])
                return CheckResult.wrong(feedback=f"{model_name_reply} is incorrect name of the 4th model\n"
                                                  f"Expected {model_name_answer}, found {model_name_reply}")

            accuracy_reply = re.findall(r'\d*\.\d+|\d+', relevant_lines[7])
            if len(accuracy_reply) != 1:
                return CheckResult.wrong(feedback=f'It should be one number in the "Accuracy:" section')
            # 1% error rate is allowed, right accuracy = 0.937
            if not 0.99 * 0.937 < float(accuracy_reply[0]) < 1.01 * 0.937:
                return CheckResult.wrong(feedback=f"Wrong accuracy for the 4th model")

            # 1st question
            answer_reply = relevant_lines[8].replace(" ", "").split('question:')
            if len(answer_reply) < 2:
                return CheckResult.wrong(
                    feedback=f'Did not find the answer to the 1st question. Make sure that you provide the answer in the correct format')
            if 'yes' != answer_reply[1].lower():
                return CheckResult.wrong(
                    feedback=f'Wrong answer to the 1st queston. Make sure that you provide the answer in the correct format')

            # 2nd question
            answer_reply = re.split(r'question:|-|,', relevant_lines[9])
            if len(answer_reply) != 5:
                return CheckResult.wrong(
                    feedback="Didn't find enough information in the answer to the 2nd question.\n"
                             "Make sure that you provide the answer in the correct format with ',' and '-' characters like in the Example section")

            if 'KNeighborsClassifier' not in answer_reply[1]:
                return CheckResult.wrong(feedback=f'Wrong answer to the 2nd question\n'
                                                  f'{answer_reply[1].replace(" ", "")} is incorrect name of the best model')
            if 'RandomForestClassifier' not in answer_reply[3]:
                return CheckResult.wrong(feedback=f'Wrong answer to the 2nd question\n'
                                                  f'{answer_reply[3].replace(" ", "")} is incorrect name of the second best model')

            return CheckResult.correct()


    if __name__ == '__main__':
        CCATest().run_tests()
  learner_created: false
- name: tests.py
  visible: false
  text: |
    from test.tests import CCATest

    if __name__ == '__main__':
        CCATest().run_tests()
  learner_created: false
feedback_link: https://hyperskill.org/learn/step/15236#comment
status: Solved
record: 3
